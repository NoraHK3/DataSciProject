{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoraHK3/DataSciProject/blob/main/DataSets/Najd_Village_Menu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTw_AZAIETRV",
        "outputId": "2506251d-3192-4108-d367-d34e8214fa5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching HTML content from the website...\n",
            "HTML content fetched successfully.\n",
            "Parsing HTML and extracting menu items...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2450230527.py:98: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
            "/tmp/ipython-input-2450230527.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'Date Scraped': datetime.utcnow().date().isoformat()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded image for 'Jareesh Soup' to najd_village_images/Jareesh_Soup.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/شوربة-جريش-Jareesh-Soup-2.png\n",
            "Item Name: Jareesh Soup\n",
            "Ingredients: Jareesh Soup lamp spices\n",
            "Local Image Path: najd_village_images/Jareesh_Soup.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Lamb Chunk Soup' to najd_village_images/Lamb_Chunk_Soup.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/شوربة-قـطع-اللـحم-Lamb-Chunk-Soup-1.png\n",
            "Item Name: Lamb Chunk Soup\n",
            "Ingredients: Lamp soup ginger\n",
            "Local Image Path: najd_village_images/Lamb_Chunk_Soup.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Veg & lamb Stew' to najd_village_images/Veg__lamb_Stew.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مرق-خضار-باللحم-Veg-lamb-Stew-1.png\n",
            "Item Name: Veg & lamb Stew\n",
            "Ingredients: Lamp vegitables\n",
            "Local Image Path: najd_village_images/Veg__lamb_Stew.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Spicy Pepper Salad' to najd_village_images/Spicy_Pepper_Salad.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/سلطة-حارة-Spicy-pepper-salad-1.png\n",
            "Item Name: Spicy Pepper Salad\n",
            "Ingredients: Tomato pepper garlic\n",
            "Local Image Path: najd_village_images/Spicy_Pepper_Salad.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Tomato with Onion Salad' to najd_village_images/Tomato_with_Onion_Salad.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/سلطة-طماطم-بالبصل-Tomato-with-onion-salad-1.png\n",
            "Item Name: Tomato with Onion Salad\n",
            "Ingredients: Tomatos Onion\n",
            "Local Image Path: najd_village_images/Tomato_with_Onion_Salad.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Taheena Salad' to najd_village_images/Taheena_Salad.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/سلطة-طحينة-Taheena-Salad-1.png\n",
            "Item Name: Taheena Salad\n",
            "Ingredients: Taheena yogurt\n",
            "Local Image Path: najd_village_images/Taheena_Salad.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Yogurt salad' to najd_village_images/Yogurt_salad.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/سـلـطة-زبادي-Yogurt-salad-1.png\n",
            "Item Name: Yogurt salad\n",
            "Ingredients: Yogurt cucumber mint\n",
            "Local Image Path: najd_village_images/Yogurt_salad.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Green Salad' to najd_village_images/Green_Salad.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/سلطة-خضراء-Green-salad-1.png\n",
            "Item Name: Green Salad\n",
            "Ingredients: Cucamber Tomatos Carrots\n",
            "Local Image Path: najd_village_images/Green_Salad.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Meat Sambosa' to najd_village_images/Meat_Sambosa.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2024/02/sambosa1.png\n",
            "Item Name: Meat Sambosa\n",
            "Ingredients: Not found\n",
            "Local Image Path: najd_village_images/Meat_Sambosa.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Cheese Sambosa' to najd_village_images/Cheese_Sambosa.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2024/02/sambosa1.png\n",
            "Item Name: Cheese Sambosa\n",
            "Ingredients: Not found\n",
            "Local Image Path: najd_village_images/Cheese_Sambosa.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Vegetables Sambosa' to najd_village_images/Vegetables_Sambosa.jpg\n",
            "--- Extracted Starter Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2024/02/sambosa1.png\n",
            "Item Name: Vegetables Sambosa\n",
            "Ingredients: Not found\n",
            "Local Image Path: najd_village_images/Vegetables_Sambosa.jpg\n",
            "-----------------------------------\n",
            "\n",
            "Downloaded image for 'Chicken Badya' to najd_village_images/Chicken_Badya.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/بادية-نصف-دجاجة-Half-Chicken-Badya_1-1.png\n",
            "Item Name: Chicken Badya\n",
            "Ingredients: jareesh Goursan rice lamb\n",
            "Local Image Path: najd_village_images/Chicken_Badya.jpg\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2450230527.py:180: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
            "/tmp/ipython-input-2450230527.py:233: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'Date Scraped': datetime.utcnow().date().isoformat()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded image for 'Chicken Saleek' to najd_village_images/Chicken_Saleek.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/سليق-نصف-دجاجة-Half-Chicken-Saleek_1-1.png\n",
            "Item Name: Chicken Saleek\n",
            "Ingredients: Rice milk meat chicken\n",
            "Local Image Path: najd_village_images/Chicken_Saleek.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Camel Vertebrae Kabsa' to najd_village_images/Camel_Vertebrae_Kabsa.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2024/12/Untitled-1.png\n",
            "Item Name: Camel Vertebrae Kabsa\n",
            "Ingredients: Not found\n",
            "Local Image Path: najd_village_images/Camel_Vertebrae_Kabsa.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Chunk of hashi meat on bone' to najd_village_images/Chunk_of_hashi_meat_on_bone.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2024/12/Untitled-1-Rec.png\n",
            "Item Name: Chunk of hashi meat on bone\n",
            "Ingredients: Not found\n",
            "Local Image Path: najd_village_images/Chunk_of_hashi_meat_on_bone.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Chicken Kabsah' to najd_village_images/Chicken_Kabsah.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/نصف-كبسة-دجاجhalf-chicken-kabsah-1.png\n",
            "Item Name: Chicken Kabsah\n",
            "Ingredients: chicken rice\n",
            "Local Image Path: najd_village_images/Chicken_Kabsah.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Shrimp Kabsah' to najd_village_images/Shrimp_Kabsah.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/كبسة-روبيان-Shrimp-Kabsah_1.png\n",
            "Item Name: Shrimp Kabsah\n",
            "Ingredients: Rice shrimp\n",
            "Local Image Path: najd_village_images/Shrimp_Kabsah.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Hashi Badya' to najd_village_images/Hashi_Badya.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/بادية-حاشي-Hashi-Badya_1.png\n",
            "Item Name: Hashi Badya\n",
            "Ingredients: jareesh Goursan rice lamb\n",
            "Local Image Path: najd_village_images/Hashi_Badya.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Lamb Badya' to najd_village_images/Lamb_Badya.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/بادية-لحم-Lamb-Badya_1-1.png\n",
            "Item Name: Lamb Badya\n",
            "Ingredients: jareesh Goursan rice lamb meat\n",
            "Local Image Path: najd_village_images/Lamb_Badya.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Hashi Kabsah' to najd_village_images/Hashi_Kabsah.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/admin-ajax.png\n",
            "Item Name: Hashi Kabsah\n",
            "Ingredients: Camel meat rice\n",
            "Local Image Path: najd_village_images/Hashi_Kabsah.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Lamb Kabsa' to najd_village_images/Lamb_Kabsa.jpg\n",
            "--- Extracted Main Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/كبسة-غنم-Lamb-Kabsah_1.png\n",
            "Item Name: Lamb Kabsa\n",
            "Ingredients: Lamb rice\n",
            "Local Image Path: najd_village_images/Lamb_Kabsa.jpg\n",
            "-----------------------------------\n",
            "\n",
            "Downloaded image for 'Liver' to najd_village_images/Liver.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/كبدة-غنم-Liver-1.png\n",
            "Item Name: Liver\n",
            "Ingredients: Lamb liver onion pepper\n",
            "Local Image Path: najd_village_images/Liver.jpg\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2450230527.py:260: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
            "/tmp/ipython-input-2450230527.py:313: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'Date Scraped': datetime.utcnow().date().isoformat()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded image for 'Matazeez' to najd_village_images/Matazeez.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مطازيز-Matazeez.png\n",
            "Item Name: Matazeez\n",
            "Ingredients: lamb wheat dough tomato sauce vegetables meat\n",
            "Local Image Path: najd_village_images/Matazeez.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Margoog' to najd_village_images/Margoog.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2025/03/margog.png\n",
            "Item Name: Margoog\n",
            "Ingredients: Lamb vegetable dough\n",
            "Local Image Path: najd_village_images/Margoog.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Goursan' to najd_village_images/Goursan.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2025/03/goursan.png\n",
            "Item Name: Goursan\n",
            "Ingredients: Lamb vegetable goursan bread\n",
            "Local Image Path: najd_village_images/Goursan.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Mogalgal' to najd_village_images/Mogalgal.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مقلقل-لحم-Mogalgal-2.png\n",
            "Item Name: Mogalgal\n",
            "Ingredients: lamb tomato sauce pepper onion\n",
            "Local Image Path: najd_village_images/Mogalgal.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Hamees' to najd_village_images/Hamees.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/حميس-Hamees-1.png\n",
            "Item Name: Hamees\n",
            "Ingredients: lamb seauteed onion\n",
            "Local Image Path: najd_village_images/Hamees.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Najd Temman' to najd_village_images/Najd_Temman.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2025/04/تمن.png\n",
            "Item Name: Najd Temman\n",
            "Ingredients: Rice chicken vegetables\n",
            "Local Image Path: najd_village_images/Najd_Temman.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Jareesh' to najd_village_images/Jareesh.jpg\n",
            "--- Extracted Dish Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2025/03/jaresh.png\n",
            "Item Name: Jareesh\n",
            "Ingredients: wheat milk granished onion lime\n",
            "Local Image Path: najd_village_images/Jareesh.jpg\n",
            "-----------------------------------\n",
            "\n",
            "Downloaded image for 'Chicken Magloba' to najd_village_images/Chicken_Magloba.jpg\n",
            "--- Extracted Magloba Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مقلوبة-دجاج-Chicken-magloba-1.png\n",
            "Item Name: Chicken Magloba\n",
            "Ingredients: Rice vegetables chicken\n",
            "Local Image Path: najd_village_images/Chicken_Magloba.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Lamb Meat Magloba' to najd_village_images/Lamb_Meat_Magloba.jpg\n",
            "--- Extracted Magloba Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مقلوبة-لحم-Lamb-magloba-1.png\n",
            "Item Name: Lamb Meat Magloba\n",
            "Ingredients: Rice lamb vegetables\n",
            "Local Image Path: najd_village_images/Lamb_Meat_Magloba.jpg\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2450230527.py:340: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
            "/tmp/ipython-input-2450230527.py:393: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'Date Scraped': datetime.utcnow().date().isoformat()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded image for 'Hashi Steam' to najd_village_images/Hashi_Steam.jpg\n",
            "--- Extracted Magloba Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مضغوط-حاشي-Hashi-steam-2.png\n",
            "Item Name: Hashi Steam\n",
            "Ingredients: Rice Camel meat\n",
            "Local Image Path: najd_village_images/Hashi_Steam.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Chicken Steam' to najd_village_images/Chicken_Steam.jpg\n",
            "--- Extracted Magloba Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مضغوط-دجاج-Chicken-steam-1.png\n",
            "Item Name: Chicken Steam\n",
            "Ingredients: Rice chicken\n",
            "Local Image Path: najd_village_images/Chicken_Steam.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Naimi Meat Steam' to najd_village_images/Naimi_Meat_Steam.jpg\n",
            "--- Extracted Magloba Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/مضغوط-لحم-Lamb-steam-1.png\n",
            "Item Name: Naimi Meat Steam\n",
            "Ingredients: Rice lamb\n",
            "Local Image Path: najd_village_images/Naimi_Meat_Steam.jpg\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2450230527.py:419: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
            "/tmp/ipython-input-2450230527.py:472: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'Date Scraped': datetime.utcnow().date().isoformat()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded image for 'Cream Caramel' to najd_village_images/Cream_Caramel.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2024/02/removal.ai_eb3f9dc9-41c5-4fbf-9343-f1e798042e38-caramel1-1.png\n",
            "Item Name: Cream Caramel\n",
            "Ingredients: \n",
            "Local Image Path: najd_village_images/Cream_Caramel.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Millet Cake (Dukh'n)' to najd_village_images/Millet_Cake_Dukhn.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2024/02/كيكة-الدخن-للموقع.png\n",
            "Item Name: Millet Cake (Dukh'n)\n",
            "Ingredients: Cake\n",
            "Local Image Path: najd_village_images/Millet_Cake_Dukhn.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Mohalabiya' to najd_village_images/Mohalabiya.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Mahlabiya-مهلبية-1.png\n",
            "Item Name: Mohalabiya\n",
            "Ingredients: milk sugar pistachio\n",
            "Local Image Path: najd_village_images/Mohalabiya.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Qishd' to najd_village_images/Qishd.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Qishd-قشد-1.png\n",
            "Item Name: Qishd\n",
            "Ingredients: dates\n",
            "Local Image Path: najd_village_images/Qishd.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Henainee' to najd_village_images/Henainee.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Henainee-حنيني-1.png\n",
            "Item Name: Henainee\n",
            "Ingredients: Date bread\n",
            "Local Image Path: najd_village_images/Henainee.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Sweet Sabeeb' to najd_village_images/Sweet_Sabeeb.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Sweet-Sabeeb-صبيب-حالي-بالعسل-1.png\n",
            "Item Name: Sweet Sabeeb\n",
            "Ingredients: wheat pancakes honey\n",
            "Local Image Path: najd_village_images/Sweet_Sabeeb.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Tatlee - Custard' to najd_village_images/Tatlee_-_Custard.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Tatlee-Custard-تطلي-1.png\n",
            "Item Name: Tatlee - Custard\n",
            "Ingredients: Custard pistachio\n",
            "Local Image Path: najd_village_images/Tatlee_-_Custard.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Mohala' to najd_village_images/Mohala.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Mohala-محلى-1.png\n",
            "Item Name: Mohala\n",
            "Ingredients: date\n",
            "Local Image Path: najd_village_images/Mohala.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Afees' to najd_village_images/Afees.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Afees-عـفيـس-1.png\n",
            "Item Name: Afees\n",
            "Ingredients: bread dates\n",
            "Local Image Path: najd_village_images/Afees.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Sabeeb Regular' to najd_village_images/Sabeeb_Regular.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Sabeeb-Regular-صـبيب-ســادة-1.png\n",
            "Item Name: Sabeeb Regular\n",
            "Ingredients: wheat pancakes\n",
            "Local Image Path: najd_village_images/Sabeeb_Regular.jpg\n",
            "-----------------------------------\n",
            "Downloaded image for 'Salty Sabeeb' to najd_village_images/Salty_Sabeeb.jpg\n",
            "--- Extracted Dessert Item Details ---\n",
            "Image URL: https://najdvillage.com/wp-content/uploads/2020/07/Salty-Sabeeb-400px.png\n",
            "Item Name: Salty Sabeeb\n",
            "Ingredients: wheat pancakes onion\n",
            "Local Image Path: najd_village_images/Salty_Sabeeb.jpg\n",
            "-----------------------------------\n",
            "\n",
            "Saving scraped data to CSV...\n",
            "Data successfully saved to najd_village_menu.csv\n",
            "\n",
            "Saving scraped data to JSON...\n",
            "Data successfully saved to najd_village_menu.json\n"
          ]
        }
      ],
      "source": [
        "import requests  # Library to make HTTP requests\n",
        "from bs4 import BeautifulSoup  # Library for parsing HTML\n",
        "import csv  # Library for handling CSV files\n",
        "import json # Library for handling JSON files\n",
        "import os  # Library for interacting with the operating system (like creating folders)\n",
        "import re  # Library for regular expressions\n",
        "import time  # Library for time-related functions\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Main Script Execution Starts Here ---\n",
        "\n",
        "# Define the URL for the menu page\n",
        "base_url = \"https://najdvillage.com/menu/?lang=en\"\n",
        "\n",
        "# Define the folder to save downloaded images\n",
        "images_folder = 'najd_village_images'\n",
        "# Check if the folder exists, and create it if it doesn't\n",
        "if not os.path.exists(images_folder):\n",
        "    os.makedirs(images_folder)\n",
        "\n",
        "# List to store all scraped data\n",
        "scraped_data = []\n",
        "\n",
        "\n",
        "# HERE\n",
        "# List of words to remove from the ingredients description\n",
        "words_to_remove = [\"sauteed\",\"&\",\"chunk\",\"fresh\",\"minced\" ,\"with\", \"and\", \"green\", \"whole\", \"preassure\",\"circles\", \"cooked\", \"in\", \"chunks\", \"stew\", \"thin\", \"brown\", \"sheets\", \"of\", \"mixed\", \"boneless\", \"cubes\", \"seasoned\", \"strips\", \"garnished\", \"crushed\", \"trio\", \"white\", \"topped\", \"broth\", \"served\", \"half\", \"back\", \"choice\", \"red\", \"succulent\", \"cut\", \"into\", \"generous\", \"pieces\", \"a\", \"fragrant\", \"bed\", \"or\", \"requires\", \"booking\", \"prepayment\", \"at\", \"least\", \"3\", \"hours\", \"in\", \"advance\", \"serves\", \"two\", \"people\", \"topped\", \"rose\", \"disks\", \"upside\", \"down\", \"together\", \"pressure\", \"steam\", \"pot\", \"our\", \"special\", \"recipe\", \"millet\", \"boiled\", \"thickened\", \"corn\", \"four\", \"crushed\", \"seedless\", \"whole\", \"sauteed\", \"browen\", \"flour\", \"butter\", \"special\", \"ground\", \"all\", \"melted\", \"small\", \"dipped\", \"in\", \"garnished\", \"paste\", \"mixed\", \"najd\", \"village\", \"fried\", \"unsweatned\", \"spring\"]\n",
        "\n",
        "def clean_ingredients(text, words_to_remove):\n",
        "    \"\"\"\n",
        "    Cleans a string by removing specified words, punctuation, and extra whitespace.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    # Remove punctuation first\n",
        "    text_without_punc = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Split the string into a list of words\n",
        "    words = text_without_punc.split()\n",
        "\n",
        "    # Create a new list with only the words not in the words_to_remove list\n",
        "    cleaned_words = [word for word in words if word.lower() not in words_to_remove]\n",
        "\n",
        "    # Join the words back into a single string\n",
        "    cleaned_text = \" \".join(cleaned_words)\n",
        "\n",
        "    # Remove any extra spaces and return the result\n",
        "    return re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
        "# TO HERE\n",
        "\n",
        "\n",
        "# --- Step 1: Fetch the HTML content ---\n",
        "print(\"Fetching HTML content from the website...\")\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "try:\n",
        "    # Send a GET request to the URL with headers and a timeout\n",
        "    response = requests.get(base_url, headers=headers, timeout=10)\n",
        "    # Raise an HTTPError if the response status code is a client or server error\n",
        "    response.raise_for_status()\n",
        "    # Store the HTML content\n",
        "    html_content = response.text\n",
        "    print(\"HTML content fetched successfully.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching {base_url}: {e}\")\n",
        "    html_content = None # Set content to None to stop the script\n",
        "\n",
        "# --- Step 2: Parse the HTML and extract data ---\n",
        "if html_content:\n",
        "    print(\"Parsing HTML and extracting menu items...\")\n",
        "    # Create a BeautifulSoup object to parse the HTML\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # --- STARTERS ---\n",
        "    # Find all div containers with the class 'item main'\n",
        "    starter_containers = soup.find_all('div', class_='item starters')\n",
        "\n",
        "    # Loop through each main container found\n",
        "    for starter in starter_containers:\n",
        "        # Initialize variables to hold the extracted data for this item\n",
        "        image_link = \"Not found\"\n",
        "        item_name = \"Not found\"\n",
        "        ingredients = \"Not found\"\n",
        "        local_image_path = \"Not found\"\n",
        "\n",
        "        # Find the image tag and extract its source URL\n",
        "        img_tag = starter.find('img', class_='item-img')\n",
        "        if img_tag:\n",
        "            image_link = img_tag.get('src')\n",
        "\n",
        "        # Find the item name from the h3 tag\n",
        "        title_tag = starter.find('div', class_='item-title')\n",
        "        if title_tag:\n",
        "            h3_tag = title_tag.find('h3')\n",
        "            # Extract only the text, ignoring other tags like <p> inside the <h3>\n",
        "            item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
        "\n",
        "        # --- Step 3: Download the image ---\n",
        "        if image_link != \"Not found\" and item_name != \"Not found\":\n",
        "            try:\n",
        "                # Sanitize the item name to create a valid filename\n",
        "                sanitized_name = re.sub(r'[^\\w\\s\\-]', '', item_name).strip().replace(' ', '_')\n",
        "                if not sanitized_name:\n",
        "                    sanitized_name = \"unknown_item\"\n",
        "\n",
        "                # Construct the full path where the image will be saved\n",
        "                image_filename = f\"{sanitized_name}.jpg\"\n",
        "                local_image_path = os.path.join(images_folder, image_filename)\n",
        "\n",
        "                # Send a request to get the image data\n",
        "                img_data = requests.get(image_link, stream=True).content\n",
        "\n",
        "                # Write the image data to a local file\n",
        "                with open(local_image_path, 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "\n",
        "                print(f\"Downloaded image for '{item_name}' to {local_image_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not download image from {image_link} for '{item_name}': {e}\")\n",
        "                local_image_path = \"Download failed\"\n",
        "\n",
        "        # Find the ingredients from the p tag inside the 'item-excerpt' div\n",
        "        ingredients_tag = starter.find('div', class_='item-excerpt')\n",
        "        if ingredients_tag:\n",
        "            p_tag = ingredients_tag.find('p', style=\"direction: rtl;\")\n",
        "            if p_tag:\n",
        "                ingredients = p_tag.get_text(strip=True)\n",
        "\n",
        "        #HERE\n",
        "        # Clean the ingredients string\n",
        "        ingredients = clean_ingredients(ingredients, words_to_remove)\n",
        "        # TO HERE\n",
        "\n",
        "        # Print the extracted data to the console\n",
        "        print(\"--- Extracted Starter Item Details ---\")\n",
        "        print(f\"Image URL: {image_link}\")\n",
        "        print(f\"Item Name: {item_name}\")\n",
        "        print(f\"Ingredients: {ingredients}\")\n",
        "        print(f\"Local Image Path: {local_image_path}\")\n",
        "        print(\"-----------------------------------\")\n",
        "\n",
        "        # Append a dictionary of the extracted data to the list\n",
        "        if item_name != \"Not found\":\n",
        "            scraped_data.append({\n",
        "                'Item Name': item_name,\n",
        "                'Ingredients': ingredients,\n",
        "                'Image Link': image_link,\n",
        "                'Local Image Path': local_image_path,\n",
        "                'Date Scraped': datetime.utcnow().date().isoformat()\n",
        "            })\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "    # --- MAIN COURSES ---\n",
        "    # Find all div containers with the class 'item main'\n",
        "    main_containers = soup.find_all('div', class_='item main')\n",
        "\n",
        "    # Loop through each main container found\n",
        "    for main in main_containers:\n",
        "        # Initialize variables to hold the extracted data for this item\n",
        "        image_link = \"Not found\"\n",
        "        item_name = \"Not found\"\n",
        "        ingredients = \"Not found\"\n",
        "        local_image_path = \"Not found\"\n",
        "\n",
        "        # Find the image tag and extract its source URL\n",
        "        img_tag = main.find('img', class_='item-img')\n",
        "        if img_tag:\n",
        "            image_link = img_tag.get('src')\n",
        "\n",
        "        # Find the item name from the h3 tag\n",
        "        title_tag = main.find('div', class_='item-title')\n",
        "        if title_tag:\n",
        "            h3_tag = title_tag.find('h3')\n",
        "            # Extract only the text, ignoring other tags like <p> inside the <h3>\n",
        "            item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
        "\n",
        "        # --- Step 3: Download the image ---\n",
        "        if image_link != \"Not found\" and item_name != \"Not found\":\n",
        "            try:\n",
        "                # Sanitize the item name to create a valid filename\n",
        "                sanitized_name = re.sub(r'[^\\w\\s\\-]', '', item_name).strip().replace(' ', '_')\n",
        "                if not sanitized_name:\n",
        "                    sanitized_name = \"unknown_item\"\n",
        "\n",
        "                # Construct the full path where the image will be saved\n",
        "                image_filename = f\"{sanitized_name}.jpg\"\n",
        "                local_image_path = os.path.join(images_folder, image_filename)\n",
        "\n",
        "                # Send a request to get the image data\n",
        "                img_data = requests.get(image_link, stream=True).content\n",
        "\n",
        "                # Write the image data to a local file\n",
        "                with open(local_image_path, 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "\n",
        "                print(f\"Downloaded image for '{item_name}' to {local_image_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not download image from {image_link} for '{item_name}': {e}\")\n",
        "                local_image_path = \"Download failed\"\n",
        "\n",
        "        # Find the ingredients from the p tag inside the 'item-excerpt' div\n",
        "        ingredients_tag = main.find('div', class_='item-excerpt')\n",
        "        if ingredients_tag:\n",
        "            p_tag = ingredients_tag.find('p', style=\"direction: rtl;\")\n",
        "            if p_tag:\n",
        "                ingredients = p_tag.get_text(strip=True)\n",
        "\n",
        "        #HERE\n",
        "        # Clean the ingredients string\n",
        "        ingredients = clean_ingredients(ingredients, words_to_remove)\n",
        "        # TO HERE\n",
        "\n",
        "        # Print the extracted data to the console\n",
        "        print(\"--- Extracted Main Item Details ---\")\n",
        "        print(f\"Image URL: {image_link}\")\n",
        "        print(f\"Item Name: {item_name}\")\n",
        "        print(f\"Ingredients: {ingredients}\")\n",
        "        print(f\"Local Image Path: {local_image_path}\")\n",
        "        print(\"-----------------------------------\")\n",
        "\n",
        "        # Append a dictionary of the extracted data to the list\n",
        "        if item_name != \"Not found\":\n",
        "            scraped_data.append({\n",
        "                'Item Name': item_name,\n",
        "                'Ingredients': ingredients,\n",
        "                'Image Link': image_link,\n",
        "                'Local Image Path': local_image_path,\n",
        "                'Date Scraped': datetime.utcnow().date().isoformat()\n",
        "            })\n",
        "\n",
        "    print()\n",
        "\n",
        "    # --- NAJDIAH DISHES ---\n",
        "    # Find all div containers with the class 'item main'\n",
        "    dish_containers = soup.find_all('div', class_='item dishes')\n",
        "\n",
        "    # Loop through each dish container found\n",
        "    for dish in dish_containers:\n",
        "      # Initialize variables to hold the extracted data for this item\n",
        "        image_link = \"Not found\"\n",
        "        item_name = \"Not found\"\n",
        "        ingredients = \"Not found\"\n",
        "        local_image_path = \"Not found\"\n",
        "\n",
        "        # Find the image tag and extract its source URL\n",
        "        img_tag = dish.find('img', class_='item-img')\n",
        "        if img_tag:\n",
        "            image_link = img_tag.get('src')\n",
        "\n",
        "        # Find the item name from the h3 tag\n",
        "        title_tag = dish.find('div', class_='item-title')\n",
        "        if title_tag:\n",
        "            h3_tag = title_tag.find('h3')\n",
        "            # Extract only the text, ignoring other tags like <p> inside the <h3>\n",
        "            item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
        "\n",
        "        # --- Step 3: Download the image ---\n",
        "        if image_link != \"Not found\" and item_name != \"Not found\":\n",
        "            try:\n",
        "                # Sanitize the item name to create a valid filename\n",
        "                sanitized_name = re.sub(r'[^\\w\\s\\-]', '', item_name).strip().replace(' ', '_')\n",
        "                if not sanitized_name:\n",
        "                    sanitized_name = \"unknown_item\"\n",
        "\n",
        "                # Construct the full path where the image will be saved\n",
        "                image_filename = f\"{sanitized_name}.jpg\"\n",
        "                local_image_path = os.path.join(images_folder, image_filename)\n",
        "\n",
        "                # Send a request to get the image data\n",
        "                img_data = requests.get(image_link, stream=True).content\n",
        "\n",
        "                # Write the image data to a local file\n",
        "                with open(local_image_path, 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "\n",
        "                print(f\"Downloaded image for '{item_name}' to {local_image_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not download image from {image_link} for '{item_name}': {e}\")\n",
        "                local_image_path = \"Download failed\"\n",
        "\n",
        "        # Find the ingredients from the p tag inside the 'item-excerpt' div\n",
        "        ingredients_tag = dish.find('div', class_='item-excerpt')\n",
        "        if ingredients_tag:\n",
        "            p_tag = ingredients_tag.find('p', style=\"direction: rtl;\")\n",
        "            if p_tag:\n",
        "                ingredients = p_tag.get_text(strip=True)\n",
        "\n",
        "        #HERE\n",
        "        # Clean the ingredients string\n",
        "        ingredients = clean_ingredients(ingredients, words_to_remove)\n",
        "        # TO HERE\n",
        "\n",
        "        # Print the extracted data to the console\n",
        "        print(\"--- Extracted Dish Item Details ---\")\n",
        "        print(f\"Image URL: {image_link}\")\n",
        "        print(f\"Item Name: {item_name}\")\n",
        "        print(f\"Ingredients: {ingredients}\")\n",
        "        print(f\"Local Image Path: {local_image_path}\")\n",
        "        print(\"-----------------------------------\")\n",
        "\n",
        "        # Append a dictionary of the extracted data to the list\n",
        "        if item_name != \"Not found\":\n",
        "            scraped_data.append({\n",
        "                'Item Name': item_name,\n",
        "                'Ingredients': ingredients,\n",
        "                'Image Link': image_link,\n",
        "                'Local Image Path': local_image_path,\n",
        "                'Date Scraped': datetime.utcnow().date().isoformat()\n",
        "            })\n",
        "\n",
        "    print()\n",
        "\n",
        "    # --- MAGLOBA DISHES ---\n",
        "    # Find all div containers with the class 'item main'\n",
        "    magloba_containers = soup.find_all('div', class_='item maglloba')\n",
        "\n",
        "    # Loop through each dish container found\n",
        "    for magloba in magloba_containers:\n",
        "      # Initialize variables to hold the extracted data for this item\n",
        "        image_link = \"Not found\"\n",
        "        item_name = \"Not found\"\n",
        "        ingredients = \"Not found\"\n",
        "        local_image_path = \"Not found\"\n",
        "\n",
        "        # Find the image tag and extract its source URL\n",
        "        img_tag = magloba.find('img', class_='item-img')\n",
        "        if img_tag:\n",
        "            image_link = img_tag.get('src')\n",
        "\n",
        "        # Find the item name from the h3 tag\n",
        "        title_tag = magloba.find('div', class_='item-title')\n",
        "        if title_tag:\n",
        "            h3_tag = title_tag.find('h3')\n",
        "            # Extract only the text, ignoring other tags like <p> inside the <h3>\n",
        "            item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
        "\n",
        "        # --- Step 3: Download the image ---\n",
        "        if image_link != \"Not found\" and item_name != \"Not found\":\n",
        "            try:\n",
        "                # Sanitize the item name to create a valid filename\n",
        "                sanitized_name = re.sub(r'[^\\w\\s\\-]', '', item_name).strip().replace(' ', '_')\n",
        "                if not sanitized_name:\n",
        "                    sanitized_name = \"unknown_item\"\n",
        "\n",
        "                # Construct the full path where the image will be saved\n",
        "                image_filename = f\"{sanitized_name}.jpg\"\n",
        "                local_image_path = os.path.join(images_folder, image_filename)\n",
        "\n",
        "                # Send a request to get the image data\n",
        "                img_data = requests.get(image_link, stream=True).content\n",
        "\n",
        "                # Write the image data to a local file\n",
        "                with open(local_image_path, 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "\n",
        "                print(f\"Downloaded image for '{item_name}' to {local_image_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not download image from {image_link} for '{item_name}': {e}\")\n",
        "                local_image_path = \"Download failed\"\n",
        "\n",
        "        # Find the ingredients from the p tag inside the 'item-excerpt' div\n",
        "        ingredients_tag = magloba.find('div', class_='item-excerpt')\n",
        "        if ingredients_tag:\n",
        "            p_tag = ingredients_tag.find('p', style=\"direction: rtl;\")\n",
        "            if p_tag:\n",
        "                ingredients = p_tag.get_text(strip=True)\n",
        "\n",
        "        #HERE\n",
        "        # Clean the ingredients string\n",
        "        ingredients = clean_ingredients(ingredients, words_to_remove)\n",
        "        # TO HERE\n",
        "\n",
        "        # Print the extracted data to the console\n",
        "        print(\"--- Extracted Magloba Item Details ---\")\n",
        "        print(f\"Image URL: {image_link}\")\n",
        "        print(f\"Item Name: {item_name}\")\n",
        "        print(f\"Ingredients: {ingredients}\")\n",
        "        print(f\"Local Image Path: {local_image_path}\")\n",
        "        print(\"-----------------------------------\")\n",
        "\n",
        "        # Append a dictionary of the extracted data to the list\n",
        "        if item_name != \"Not found\":\n",
        "            scraped_data.append({\n",
        "                'Item Name': item_name,\n",
        "                'Ingredients': ingredients,\n",
        "                'Image Link': image_link,\n",
        "                'Local Image Path': local_image_path,\n",
        "                'Date Scraped': datetime.utcnow().date().isoformat()\n",
        "            })\n",
        "\n",
        "\n",
        "    # --- DESSERTS ---\n",
        "    # Find all div containers with the class 'item main'\n",
        "    dessert_containers = soup.find_all('div', class_='item dessert')\n",
        "\n",
        "    # Loop through each dish container found\n",
        "    for dessert in dessert_containers:\n",
        "      # Initialize variables to hold the extracted data for this item\n",
        "        image_link = \"Not found\"\n",
        "        item_name = \"Not found\"\n",
        "        ingredients = \"Not found\"\n",
        "        local_image_path = \"Not found\"\n",
        "\n",
        "        # Find the image tag and extract its source URL\n",
        "        img_tag = dessert.find('img', class_='item-img')\n",
        "        if img_tag:\n",
        "            image_link = img_tag.get('src')\n",
        "\n",
        "        # Find the item name from the h3 tag\n",
        "        title_tag = dessert.find('div', class_='item-title')\n",
        "        if title_tag:\n",
        "            h3_tag = title_tag.find('h3')\n",
        "            # Extract only the text, ignoring other tags like <p> inside the <h3>\n",
        "            item_name = \"\".join(h3_tag.find_all(text=True, recursive=False)).strip()\n",
        "\n",
        "        # --- Step 3: Download the image ---\n",
        "        if image_link != \"Not found\" and item_name != \"Not found\":\n",
        "            try:\n",
        "                # Sanitize the item name to create a valid filename\n",
        "                sanitized_name = re.sub(r'[^\\w\\s\\-]', '', item_name).strip().replace(' ', '_')\n",
        "                if not sanitized_name:\n",
        "                    sanitized_name = \"unknown_item\"\n",
        "\n",
        "                # Construct the full path where the image will be saved\n",
        "                image_filename = f\"{sanitized_name}.jpg\"\n",
        "                local_image_path = os.path.join(images_folder, image_filename)\n",
        "\n",
        "                # Send a request to get the image data\n",
        "                img_data = requests.get(image_link, stream=True).content\n",
        "\n",
        "                # Write the image data to a local file\n",
        "                with open(local_image_path, 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "\n",
        "                print(f\"Downloaded image for '{item_name}' to {local_image_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not download image from {image_link} for '{item_name}': {e}\")\n",
        "                local_image_path = \"Download failed\"\n",
        "\n",
        "        # Find the ingredients from the p tag inside the 'item-excerpt' div\n",
        "        ingredients_tag = dessert.find('div', class_='item-excerpt')\n",
        "        if ingredients_tag:\n",
        "            p_tag = ingredients_tag.find('p', style=\"direction: rtl;\")\n",
        "            if p_tag:\n",
        "              ingredients = p_tag.get_text(strip=True)\n",
        "\n",
        "        #HERE\n",
        "        # Clean the ingredients string\n",
        "        ingredients = clean_ingredients(ingredients, words_to_remove)\n",
        "        # TO HERE\n",
        "\n",
        "        # Print the extracted data to the console\n",
        "        print(\"--- Extracted Dessert Item Details ---\")\n",
        "        print(f\"Image URL: {image_link}\")\n",
        "        print(f\"Item Name: {item_name}\")\n",
        "        print(f\"Ingredients: {ingredients}\")\n",
        "        print(f\"Local Image Path: {local_image_path}\")\n",
        "        print(\"-----------------------------------\")\n",
        "\n",
        "        # Append a dictionary of the extracted data to the list\n",
        "        if item_name != \"Not found\":\n",
        "            scraped_data.append({\n",
        "                'Item Name': item_name,\n",
        "                'Ingredients': ingredients,\n",
        "                'Image Link': image_link,\n",
        "                'Local Image Path': local_image_path,\n",
        "                'Date Scraped': datetime.utcnow().date().isoformat()\n",
        "            })\n",
        "\n",
        "\n",
        "# --- Step 4: Save the scraped data to a CSV file ---\n",
        "if scraped_data:\n",
        "    print(\"\\nSaving scraped data to CSV...\")\n",
        "    csv_filename = 'najd_village_menu.csv'\n",
        "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Item Name', 'Ingredients', 'Image Link', 'Local Image Path', 'Date Scraped']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(scraped_data)\n",
        "    print(f\"Data successfully saved to {csv_filename}\")\n",
        "\n",
        "\n",
        "    # --- Step 5: Save the scraped data to a JSON file ---\n",
        "    print(\"\\nSaving scraped data to JSON...\")\n",
        "    json_filename = 'najd_village_menu.json'\n",
        "    with open(json_filename, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(scraped_data, jsonfile, indent=4, ensure_ascii=False)\n",
        "    print(f\"Data successfully saved to {json_filename}\")\n",
        "\n",
        "else:\n",
        "    print(\"No data was scraped to save.\")\n"
      ]
    }
  ]
}