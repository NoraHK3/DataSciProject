{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGLyfhYv7NOaVeVwL7rVly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoraHK3/DataSciProject/blob/main/translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OVERRIDES_JSON = \"overrides_expanded.json\"\n"
      ],
      "metadata": {
        "id": "R9DYk_0Huf5Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9pjYhLHpvIl",
        "outputId": "a05aa8cf-6b3d-40b9-bbaf-744872b44053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Using overrides file: overrides.json\n",
            "   Loaded overrides: 0 (normalized Arabic keys: 0)\n",
            "üßπ Purged 0 cache entries that now have overrides\n",
            "üìù Translating columns: ['dish_name', 'classifications', 'image_file', 'scrape_date']\n",
            "‚û°Ô∏è  Translating: dish_name\n",
            "‚û°Ô∏è  Translating: classifications\n",
            "‚û°Ô∏è  Translating: image_file\n",
            "‚û°Ô∏è  Translating: scrape_date\n",
            "‚úÖ Done: SaudiFoodFile_english_FIXED.csv\n",
            "üíæ Cache: translation_cache.csv\n",
            "‚úçÔ∏è Overrides file in use: overrides.json\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Translator (Deep) with Expanded Overrides + Cache Purge + Debug\n",
        "# ============================================\n",
        "\n",
        "!pip install -q pandas deep-translator\n",
        "\n",
        "import os, re, json, pandas as pd\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "INPUT_CSV  = \"SaudiFoodFile.csv\"\n",
        "OUTPUT_CSV = \"SaudiFoodFile_english_FIXED.csv\"\n",
        "CACHE_CSV  = \"translation_cache.csv\"\n",
        "\n",
        "# Prefer expanded overrides if present\n",
        "OVR_EXP   = \"overrides_expanded.json\"\n",
        "OVR_BASE  = \"overrides.json\"\n",
        "OVERRIDES_JSON = OVR_EXP if os.path.exists(OVR_EXP) else OVR_BASE\n",
        "\n",
        "HANDLE_CLASSIFICATIONS = True  # split 'classifications' by '|'\n",
        "TRANSLATE_COLS = None          # None -> all object columns\n",
        "\n",
        "# ---------- helpers ----------\n",
        "AR_DIAC = re.compile(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u06D6-\\u06ED]\")\n",
        "def norm_ar(s: str) -> str:\n",
        "    s = AR_DIAC.sub(\"\", s)\n",
        "    s = s.replace(\"\\u0640\",\"\")\n",
        "    s = s.replace(\"ÿ£\",\"ÿß\").replace(\"ÿ•\",\"ÿß\").replace(\"ÿ¢\",\"ÿß\")\n",
        "    s = s.replace(\"Ÿâ\",\"Ÿä\").replace(\"ÿ¶\",\"Ÿä\").replace(\"ÿ§\",\"Ÿà\").replace(\"Ÿ±\",\"ÿß\")\n",
        "    return s\n",
        "\n",
        "def key_norm(x: str) -> str:\n",
        "    return norm_ar(str(x).strip().lower())\n",
        "\n",
        "POST_FIX = {\n",
        "    \"black lemon\": \"black lime\",\n",
        "    \"nail\": \"cloves\",\n",
        "    \"cardamon\": \"cardamom\",\n",
        "    \"yougurt\": \"yogurt\",\n",
        "    \"youghurt\": \"yogurt\",\n",
        "}\n",
        "\n",
        "def apply_postfix(en: str) -> str:\n",
        "    return POST_FIX.get(str(en).strip().lower(), str(en).strip())\n",
        "\n",
        "# ---------- load data ----------\n",
        "# CSV\n",
        "try:\n",
        "    df = pd.read_csv(INPUT_CSV, encoding=\"utf-8\")\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv(INPUT_CSV, encoding=\"cp1256\")\n",
        "\n",
        "# Overrides\n",
        "if os.path.exists(OVERRIDES_JSON):\n",
        "    with open(OVERRIDES_JSON, \"r\", encoding=\"utf-8\") as f:\n",
        "        OV = json.load(f)\n",
        "else:\n",
        "    OV = {}\n",
        "\n",
        "# Normalized override view (for Arabic variant matching)\n",
        "OV_NORM = {key_norm(k): v for k, v in OV.items() if re.search(r\"[\\u0600-\\u06FF]\", k)}\n",
        "print(f\"üîß Using overrides file: {OVERRIDES_JSON}\")\n",
        "print(f\"   Loaded overrides: {len(OV)} (normalized Arabic keys: {len(OV_NORM)})\")\n",
        "# show a few samples for sanity\n",
        "for i,(k,v) in enumerate(list(OV.items())[:8]):\n",
        "    print(f\"   ‚Ä¢ {k}  ->  {v}\")\n",
        "    if i>=7: break\n",
        "\n",
        "# Cache (load then purge entries that now have overrides)\n",
        "if os.path.exists(CACHE_CSV):\n",
        "    cache_df = pd.read_csv(CACHE_CSV)\n",
        "    CACHE = dict(cache_df.values)  # {raw: english}\n",
        "else:\n",
        "    CACHE = {}\n",
        "\n",
        "def override_lookup(text: str):\n",
        "    if text in OV:\n",
        "        return OV[text]\n",
        "    kn = key_norm(text)\n",
        "    if kn in OV_NORM:\n",
        "        return OV_NORM[kn]\n",
        "    return None\n",
        "\n",
        "# Purge cache entries that should now be overridden\n",
        "purged = 0\n",
        "to_del = []\n",
        "for raw in list(CACHE.keys()):\n",
        "    if override_lookup(raw):\n",
        "        to_del.append(raw)\n",
        "for raw in to_del:\n",
        "    CACHE.pop(raw, None)\n",
        "    purged += 1\n",
        "print(f\"üßπ Purged {purged} cache entries that now have overrides\")\n",
        "\n",
        "translator = GoogleTranslator(source=\"auto\", target=\"en\")\n",
        "\n",
        "def translate_text(text: str) -> str:\n",
        "    if pd.isna(text) or str(text).strip() == \"\":\n",
        "        return text\n",
        "    s = str(text).strip()\n",
        "\n",
        "    # 1) override wins (exact or normalized)\n",
        "    ov = override_lookup(s)\n",
        "    if ov:\n",
        "        return ov\n",
        "\n",
        "    # 2) cache\n",
        "    if s in CACHE:\n",
        "        return CACHE[s]\n",
        "\n",
        "    # 3) machine translation\n",
        "    try:\n",
        "        en = translator.translate(s) or s\n",
        "        en = apply_postfix(en)\n",
        "    except Exception:\n",
        "        en = s  # keep original on error\n",
        "\n",
        "    CACHE[s] = en\n",
        "    return en\n",
        "\n",
        "def translate_classifications_cell(cell: str) -> str:\n",
        "    parts = [p.strip() for p in str(cell).split(\"|\")]\n",
        "    out = []\n",
        "    for p in parts:\n",
        "        if not p:\n",
        "            continue\n",
        "        ov = override_lookup(p)\n",
        "        en = ov if ov else translate_text(p)\n",
        "        out.append(str(en).lower())\n",
        "    return \" | \".join(out)\n",
        "\n",
        "# ---------- choose columns ----------\n",
        "obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
        "cols = obj_cols if TRANSLATE_COLS is None else [c for c in TRANSLATE_COLS if c in df.columns]\n",
        "print(f\"üìù Translating columns: {cols}\")\n",
        "\n",
        "# ---------- translate ----------\n",
        "for col in cols:\n",
        "    print(f\"‚û°Ô∏è  Translating: {col}\")\n",
        "    if HANDLE_CLASSIFICATIONS and col.lower() == \"classifications\":\n",
        "        df[col] = df[col].astype(str).apply(translate_classifications_cell)\n",
        "    else:\n",
        "        df[col] = df[col].apply(translate_text)\n",
        "\n",
        "# ---------- save ----------\n",
        "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(list(CACHE.items()), columns=[\"raw\",\"english\"]).to_csv(CACHE_CSV, index=False)\n",
        "\n",
        "print(f\"‚úÖ Done: {OUTPUT_CSV}\")\n",
        "print(f\"üíæ Cache: {CACHE_CSV}\")\n",
        "print(f\"‚úçÔ∏è Overrides file in use: {OVERRIDES_JSON}\")\n"
      ]
    }
  ]
}